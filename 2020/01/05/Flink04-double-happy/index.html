<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Flink04--double_happy | DoubleHappy or Jepson</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  
  
  <meta name="description" content="12345678910111213141516171819202122232425262728293031323334面试题：谈谈你对Flink ON YARN执行流程的理解acks=all 数据一定不会丢失吗如何保证Kafka消费者数据全局有序？ 伪命题    producer    storage    consumer10分区 3个消费者    哪个分区被谁消费C0C1T0    0 1 2">
<meta property="og:type" content="article">
<meta property="og:title" content="Flink04--double_happy">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2020&#x2F;01&#x2F;05&#x2F;Flink04-double-happy&#x2F;index.html">
<meta property="og:site_name" content="DoubleHappy or Jepson">
<meta property="og:description" content="12345678910111213141516171819202122232425262728293031323334面试题：谈谈你对Flink ON YARN执行流程的理解acks=all 数据一定不会丢失吗如何保证Kafka消费者数据全局有序？ 伪命题    producer    storage    consumer10分区 3个消费者    哪个分区被谁消费C0C1T0    0 1 2">
<meta property="og:locale" content="en">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105201512668.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105202554890.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105203620172.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105203915909.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105210441990.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105210608282.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105210959821.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105211034704.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105211557264.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105212016595.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105214018381.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105215637367.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105223922233.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;2020010523100919.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105231116600.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
<meta property="og:updated_time" content="2020-01-05T15:48:46.082Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;img-blog.csdnimg.cn&#x2F;20200105201512668.png?x-oss-process=image&#x2F;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70">
  
    <link rel="alternate" href="/atom.xml" title="DoubleHappy or Jepson" type="application/atom+xml">
  
  
    <link rel="icon" href="/images/default-avatar.jpg">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/css/highlight.css">
</head>

<body>
  <div id="fullpage" class="mobile-nav-right">
    
      <div id="wrapper" title="图片来自网络">
    
    
      <header id="header">
  <div id="nav-toggle" class="nav-toggle"></div>
  <div class="head-box global-width">
    <nav class="nav-box nav-right">
      
        <a class="nav-item" href="/archives" title
        
        >首页</a>
      
        <a class="nav-item" href="/archives" title
        
        >归档</a>
      
    </nav>
  </div>
</header>
      <div id="middlecontent" title class="global-width sidebar-right">
        <section id="main"><article id="post-Flink04-double-happy" class="article global-container article-type-post" itemscope itemprop="blogPost">
  
    <header class="article-header">
      
  
    <h1 class="article-title" itemprop="name">
      Flink04--double_happy
    </h1>
  

    </header>
  
  <div class="article-meta">
    <a href="/2020/01/05/Flink04-double-happy/" class="article-date">
  <time datetime="2020-01-05T15:47:43.000Z" itemprop="datePublished">2020-01-05</time>
</a>
    
    
  </div>
  
    <span id="busuanzi_container_page_pv">
      本文总阅读量<span id="busuanzi_value_page_pv"></span>次
    </span>
  

  <div class="article-inner">
    
    <div class="article-content article-content-cloud" itemprop="articleBody">
      
        <div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">面试题：谈谈你对Flink ON YARN执行流程的理解</span><br><span class="line"></span><br><span class="line">acks=all 数据一定不会丢失吗</span><br><span class="line">如何保证Kafka消费者数据全局有序？ 伪命题</span><br><span class="line">    producer</span><br><span class="line">    storage</span><br><span class="line">    consumer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">10分区 3个消费者</span><br><span class="line">    哪个分区被谁消费</span><br><span class="line"></span><br><span class="line">C0</span><br><span class="line">C1</span><br><span class="line"></span><br><span class="line">T0</span><br><span class="line">    0 1 2</span><br><span class="line">T1</span><br><span class="line">    0 1 2</span><br><span class="line"></span><br><span class="line">6/2</span><br><span class="line">We then divide the number of partitions by the total number of</span><br><span class="line">consumers to determine the number of partitions to assign to each consumer. If it does not evenly</span><br><span class="line">divide, then the first few consumers will have one extra partition.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">t0p0, t1p0, t1p1, t2p0, t2p1, t2p2</span><br><span class="line"></span><br><span class="line">C0 is subscribed to t0;           t0p0</span><br><span class="line">C1 is subscribed to t0, t1;       t0p0, t1p0, t1p1</span><br><span class="line">C2 is subscribed to t0, t1, t2.   t0p0, t1p0, t1p1, t2p0, t2p1, t2p2</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Sinl 到 HBase：</span><br><span class="line">	1种.自定义 RichSinkFunction  或者 带并行的</span><br><span class="line">	2种 .  Hadoop Compatibility Beta</span><br><span class="line">			You can:</span><br><span class="line">			use Hadoop’s Writable data types in Flink programs.</span><br><span class="line">			use any Hadoop InputFormat as a DataSource.</span><br><span class="line">			use any Hadoop OutputFormat as a DataSink.</span><br><span class="line">			use a Hadoop Mapper as FlatMapFunction.</span><br><span class="line">			use a Hadoop Reducer as GroupReduceFunction.</span><br></pre></td></tr></table></figure></div>
<p><strong>Hadoop Compatibility Beta</strong><br><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/dev/batch/hadoop_compatibility.html#hadoop-compatibility-beta" target="_blank" rel="noopener">Hadoop Compatibility Beta</a></p>
<p><img src="https://img-blog.csdnimg.cn/20200105201512668.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">也就是说  ：</span><br><span class="line">	写入HBase 有两种方式</span><br><span class="line">		1.自定义 Sink</span><br><span class="line">		2.Flink-Hadoop 的Api</span><br></pre></td></tr></table></figure></div>

<p><strong>环境部署</strong><br><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/flinkDev/building.html#building-flink-from-source" target="_blank" rel="noopener">Building Flink from Source</a></p>
<p>部署：<br><img src="https://img-blog.csdnimg.cn/20200105202554890.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">部署：</span><br><span class="line">	1.本地的 </span><br><span class="line">	2.yarn</span><br><span class="line">作为重点。</span><br></pre></td></tr></table></figure></div>
<p><strong>Local</strong><br><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/getting-started/tutorials/local_setup.html#local-setup-tutorial" target="_blank" rel="noopener">Local Setup Tutorial</a></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">1.启动集群：</span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 flink]$ bin/start-cluster.sh </span><br><span class="line">Starting cluster.</span><br><span class="line">Starting standalonesession daemon on host hadoop101.</span><br><span class="line">Starting taskexecutor daemon on host hadoop101.</span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">	1.Starting standalonesession </span><br><span class="line">	2.Starting taskexecutor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 flink]$ jps</span><br><span class="line">4688 TaskManagerRunner</span><br><span class="line">4722 Jps</span><br><span class="line">4258 StandaloneSessionClusterEntrypoint</span><br><span class="line">[double_happy@hadoop101 flink]$ </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2.看页面 端口 8081</span><br></pre></td></tr></table></figure></div>
<p><img src="https://img-blog.csdnimg.cn/20200105203620172.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/20200105203915909.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">按照官网给的案例：</span><br><span class="line"></span><br><span class="line">object SocketWindowWordCount &#123;</span><br><span class="line">  def main(args: Array[String]) : Unit = &#123;</span><br><span class="line">    val port: Int = try &#123;</span><br><span class="line">      ParameterTool.fromArgs(args).getInt(&quot;port&quot;)</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      case e: Exception =&gt; &#123;</span><br><span class="line">        System.err.println(&quot;No port specified. Please run &apos;SocketWindowWordCount --host &lt;host&gt; --port &lt;port&gt;&apos;&quot;)</span><br><span class="line">        return</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    val host: String = try &#123;</span><br><span class="line">      ParameterTool.fromArgs(args).get(&quot;host&quot;)</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      case e: Exception =&gt; &#123;</span><br><span class="line">        System.err.println(&quot;No port specified. Please run &apos;SocketWindowWordCount --host &lt;host&gt; --port &lt;port&gt;&apos;&quot;)</span><br><span class="line">        return</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line">    val text = env.socketTextStream(host, port)</span><br><span class="line">    val windowCounts = text</span><br><span class="line">      .flatMap &#123; w =&gt; w.split(&quot;,&quot;) &#125;</span><br><span class="line">      .map &#123; w =&gt; WordWithCount(w, 1) &#125;</span><br><span class="line">      .keyBy(&quot;word&quot;)</span><br><span class="line">      .sum(&quot;count&quot;)</span><br><span class="line"></span><br><span class="line">    windowCounts.print().setParallelism(1)</span><br><span class="line"></span><br><span class="line">    env.execute(&quot;Socket Window WordCount&quot;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  case class WordWithCount(word: String, count: Long)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">	打包上传到本地</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.启动 端口 nc ：nc -lk 9998</span><br><span class="line"></span><br><span class="line">2.提交flink jar 包</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br></pre></td><td class="code"><pre><span class="line">[double_happy@hadoop101 bin]$ ./flink</span><br><span class="line">2020-01-05 23:20:00,751 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - Found Yarn properties file under /tmp/.yarn-properties-double_happy.</span><br><span class="line">2020-01-05 23:20:00,751 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - Found Yarn properties file under /tmp/.yarn-properties-double_happy.</span><br><span class="line">./flink &lt;ACTION&gt; [OPTIONS] [ARGUMENTS]</span><br><span class="line"></span><br><span class="line">The following actions are available:</span><br><span class="line"></span><br><span class="line">Action &quot;run&quot; compiles and runs a program.</span><br><span class="line"></span><br><span class="line">  Syntax: run [OPTIONS] &lt;jar-file&gt; &lt;arguments&gt;</span><br><span class="line">  &quot;run&quot; action options:</span><br><span class="line">     -c,--class &lt;classname&gt;               Class with the program entry point</span><br><span class="line">                                          (&quot;main()&quot; method or &quot;getPlan()&quot;</span><br><span class="line">                                          method). Only needed if the JAR file</span><br><span class="line">                                          does not specify the class in its</span><br><span class="line">                                          manifest.</span><br><span class="line">     -C,--classpath &lt;url&gt;                 Adds a URL to each user code</span><br><span class="line">                                          classloader  on all nodes in the</span><br><span class="line">                                          cluster. The paths must specify a</span><br><span class="line">                                          protocol (e.g. file://) and be</span><br><span class="line">                                          accessible on all nodes (e.g. by means</span><br><span class="line">                                          of a NFS share). You can use this</span><br><span class="line">                                          option multiple times for specifying</span><br><span class="line">                                          more than one URL. The protocol must</span><br><span class="line">                                          be supported by the &#123;@link</span><br><span class="line">                                          java.net.URLClassLoader&#125;.</span><br><span class="line">     -d,--detached                        If present, runs the job in detached</span><br><span class="line">                                          mode</span><br><span class="line">     -n,--allowNonRestoredState           Allow to skip savepoint state that</span><br><span class="line">                                          cannot be restored. You need to allow</span><br><span class="line">                                          this if you removed an operator from</span><br><span class="line">                                          your program that was part of the</span><br><span class="line">                                          program when the savepoint was</span><br><span class="line">                                          triggered.</span><br><span class="line">     -p,--parallelism &lt;parallelism&gt;       The parallelism with which to run the</span><br><span class="line">                                          program. Optional flag to override the</span><br><span class="line">                                          default value specified in the</span><br><span class="line">                                          configuration.</span><br><span class="line">     -py,--python &lt;python&gt;                Python script with the program entry</span><br><span class="line">                                          point. The dependent resources can be</span><br><span class="line">                                          configured with the `--pyFiles`</span><br><span class="line">                                          option.</span><br><span class="line">     -pyfs,--pyFiles &lt;pyFiles&gt;            Attach custom python files for job.</span><br><span class="line">                                          Comma can be used as the separator to</span><br><span class="line">                                          specify multiple files. The standard</span><br><span class="line">                                          python resource file suffixes such as</span><br><span class="line">                                          .py/.egg/.zip are all supported.(eg:</span><br><span class="line">                                          --pyFiles</span><br><span class="line">                                          file:///tmp/myresource.zip,hdfs:///$na</span><br><span class="line">                                          menode_address/myresource2.zip)</span><br><span class="line">     -pym,--pyModule &lt;pyModule&gt;           Python module with the program entry</span><br><span class="line">                                          point. This option must be used in</span><br><span class="line">                                          conjunction with `--pyFiles`.</span><br><span class="line">     -q,--sysoutLogging                   If present, suppress logging output to</span><br><span class="line">                                          standard out.</span><br><span class="line">     -s,--fromSavepoint &lt;savepointPath&gt;   Path to a savepoint to restore the job</span><br><span class="line">                                          from (for example</span><br><span class="line">                                          hdfs:///flink/savepoint-1537).</span><br><span class="line">     -sae,--shutdownOnAttachedExit        If the job is submitted in attached</span><br><span class="line">                                          mode, perform a best-effort cluster</span><br><span class="line">                                          shutdown when the CLI is terminated</span><br><span class="line">                                          abruptly, e.g., in response to a user</span><br><span class="line">                                          interrupt, such as typing Ctrl + C.</span><br><span class="line">  Options for yarn-cluster mode:</span><br><span class="line">     -d,--detached                        If present, runs the job in detached</span><br><span class="line">                                          mode</span><br><span class="line">     -m,--jobmanager &lt;arg&gt;                Address of the JobManager (master) to</span><br><span class="line">                                          which to connect. Use this flag to</span><br><span class="line">                                          connect to a different JobManager than</span><br><span class="line">                                          the one specified in the</span><br><span class="line">                                          configuration.</span><br><span class="line">     -sae,--shutdownOnAttachedExit        If the job is submitted in attached</span><br><span class="line">                                          mode, perform a best-effort cluster</span><br><span class="line">                                          shutdown when the CLI is terminated</span><br><span class="line">                                          abruptly, e.g., in response to a user</span><br><span class="line">                                          interrupt, such as typing Ctrl + C.</span><br><span class="line">     -yat,--yarnapplicationType &lt;arg&gt;     Set a custom application type for the</span><br><span class="line">                                          application on YARN</span><br><span class="line">     -yD &lt;property=value&gt;                 use value for given property</span><br><span class="line">     -yd,--yarndetached                   If present, runs the job in detached</span><br><span class="line">                                          mode (deprecated; use non-YARN</span><br><span class="line">                                          specific option instead)</span><br><span class="line">     -yh,--yarnhelp                       Help for the Yarn session CLI.</span><br><span class="line">     -yid,--yarnapplicationId &lt;arg&gt;       Attach to running YARN session</span><br><span class="line">     -yj,--yarnjar &lt;arg&gt;                  Path to Flink jar file</span><br><span class="line">     -yjm,--yarnjobManagerMemory &lt;arg&gt;    Memory for JobManager Container with</span><br><span class="line">                                          optional unit (default: MB)</span><br><span class="line">     -yn,--yarncontainer &lt;arg&gt;            Number of YARN container to allocate</span><br><span class="line">                                          (=Number of Task Managers)</span><br><span class="line">     -ynl,--yarnnodeLabel &lt;arg&gt;           Specify YARN node label for the YARN</span><br><span class="line">                                          application</span><br><span class="line">     -ynm,--yarnname &lt;arg&gt;                Set a custom name for the application</span><br><span class="line">                                          on YARN</span><br><span class="line">     -yq,--yarnquery                      Display available YARN resources</span><br><span class="line">                                          (memory, cores)</span><br><span class="line">     -yqu,--yarnqueue &lt;arg&gt;               Specify YARN queue.</span><br><span class="line">     -ys,--yarnslots &lt;arg&gt;                Number of slots per TaskManager</span><br><span class="line">     -yst,--yarnstreaming                 Start Flink in streaming mode</span><br><span class="line">     -yt,--yarnship &lt;arg&gt;                 Ship files in the specified directory</span><br><span class="line">                                          (t for transfer)</span><br><span class="line">     -ytm,--yarntaskManagerMemory &lt;arg&gt;   Memory per TaskManager Container with</span><br><span class="line">                                          optional unit (default: MB)</span><br><span class="line">     -yz,--yarnzookeeperNamespace &lt;arg&gt;   Namespace to create the Zookeeper</span><br><span class="line">                                          sub-paths for high availability mode</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;        Namespace to create the Zookeeper</span><br><span class="line">                                          sub-paths for high availability mode</span><br><span class="line"></span><br><span class="line">  Options for default mode:</span><br><span class="line">     -m,--jobmanager &lt;arg&gt;           Address of the JobManager (master) to which</span><br><span class="line">                                     to connect. Use this flag to connect to a</span><br><span class="line">                                     different JobManager than the one specified</span><br><span class="line">                                     in the configuration.</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;   Namespace to create the Zookeeper sub-paths</span><br><span class="line">                                     for high availability mode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Action &quot;info&quot; shows the optimized execution plan of the program (JSON).</span><br><span class="line"></span><br><span class="line">  Syntax: info [OPTIONS] &lt;jar-file&gt; &lt;arguments&gt;</span><br><span class="line">  &quot;info&quot; action options:</span><br><span class="line">     -c,--class &lt;classname&gt;           Class with the program entry point</span><br><span class="line">                                      (&quot;main()&quot; method or &quot;getPlan()&quot; method).</span><br><span class="line">                                      Only needed if the JAR file does not</span><br><span class="line">                                      specify the class in its manifest.</span><br><span class="line">     -p,--parallelism &lt;parallelism&gt;   The parallelism with which to run the</span><br><span class="line">                                      program. Optional flag to override the</span><br><span class="line">                                      default value specified in the</span><br><span class="line">                                      configuration.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Action &quot;list&quot; lists running and scheduled programs.</span><br><span class="line"></span><br><span class="line">  Syntax: list [OPTIONS]</span><br><span class="line">  &quot;list&quot; action options:</span><br><span class="line">     -r,--running     Show only running programs and their JobIDs</span><br><span class="line">     -s,--scheduled   Show only scheduled programs and their JobIDs</span><br><span class="line">  Options for yarn-cluster mode:</span><br><span class="line">     -m,--jobmanager &lt;arg&gt;            Address of the JobManager (master) to</span><br><span class="line">                                      which to connect. Use this flag to connect</span><br><span class="line">                                      to a different JobManager than the one</span><br><span class="line">                                      specified in the configuration.</span><br><span class="line">     -yid,--yarnapplicationId &lt;arg&gt;   Attach to running YARN session</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;    Namespace to create the Zookeeper</span><br><span class="line">                                      sub-paths for high availability mode</span><br><span class="line"></span><br><span class="line">  Options for default mode:</span><br><span class="line">     -m,--jobmanager &lt;arg&gt;           Address of the JobManager (master) to which</span><br><span class="line">                                     to connect. Use this flag to connect to a</span><br><span class="line">                                     different JobManager than the one specified</span><br><span class="line">                                     in the configuration.</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;   Namespace to create the Zookeeper sub-paths</span><br><span class="line">                                     for high availability mode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Action &quot;stop&quot; stops a running program with a savepoint (streaming jobs only).</span><br><span class="line"></span><br><span class="line">  Syntax: stop [OPTIONS] &lt;Job ID&gt;</span><br><span class="line">  &quot;stop&quot; action options:</span><br><span class="line">     -d,--drain                           Send MAX_WATERMARK before taking the</span><br><span class="line">                                          savepoint and stopping the pipelne.</span><br><span class="line">     -p,--savepointPath &lt;savepointPath&gt;   Path to the savepoint (for example</span><br><span class="line">                                          hdfs:///flink/savepoint-1537). If no</span><br><span class="line">                                          directory is specified, the configured</span><br><span class="line">                                          default will be used</span><br><span class="line">                                          (&quot;state.savepoints.dir&quot;).</span><br><span class="line">  Options for yarn-cluster mode:</span><br><span class="line">     -m,--jobmanager &lt;arg&gt;            Address of the JobManager (master) to</span><br><span class="line">                                      which to connect. Use this flag to connect</span><br><span class="line">                                      to a different JobManager than the one</span><br><span class="line">                                      specified in the configuration.</span><br><span class="line">     -yid,--yarnapplicationId &lt;arg&gt;   Attach to running YARN session</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;    Namespace to create the Zookeeper</span><br><span class="line">                                      sub-paths for high availability mode</span><br><span class="line"></span><br><span class="line">  Options for default mode:</span><br><span class="line">     -m,--jobmanager &lt;arg&gt;           Address of the JobManager (master) to which</span><br><span class="line">                                     to connect. Use this flag to connect to a</span><br><span class="line">                                     different JobManager than the one specified</span><br><span class="line">                                     in the configuration.</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;   Namespace to create the Zookeeper sub-paths</span><br><span class="line">                                     for high availability mode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Action &quot;cancel&quot; cancels a running program.</span><br><span class="line"></span><br><span class="line">  Syntax: cancel [OPTIONS] &lt;Job ID&gt;</span><br><span class="line">  &quot;cancel&quot; action options:</span><br><span class="line">     -s,--withSavepoint &lt;targetDirectory&gt;   **DEPRECATION WARNING**: Cancelling</span><br><span class="line">                                            a job with savepoint is deprecated.</span><br><span class="line">                                            Use &quot;stop&quot; instead.</span><br><span class="line">                                            Trigger savepoint and cancel job.</span><br><span class="line">                                            The target directory is optional. If</span><br><span class="line">                                            no directory is specified, the</span><br><span class="line">                                            configured default directory</span><br><span class="line">                                            (state.savepoints.dir) is used.</span><br><span class="line">  Options for yarn-cluster mode:</span><br><span class="line">     -m,--jobmanager &lt;arg&gt;            Address of the JobManager (master) to</span><br><span class="line">                                      which to connect. Use this flag to connect</span><br><span class="line">                                      to a different JobManager than the one</span><br><span class="line">                                      specified in the configuration.</span><br><span class="line">     -yid,--yarnapplicationId &lt;arg&gt;   Attach to running YARN session</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;    Namespace to create the Zookeeper</span><br><span class="line">                                      sub-paths for high availability mode</span><br><span class="line"></span><br><span class="line">  Options for default mode:</span><br><span class="line">     -m,--jobmanager &lt;arg&gt;           Address of the JobManager (master) to which</span><br><span class="line">                                     to connect. Use this flag to connect to a</span><br><span class="line">                                     different JobManager than the one specified</span><br><span class="line">                                     in the configuration.</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;   Namespace to create the Zookeeper sub-paths</span><br><span class="line">                                     for high availability mode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Action &quot;savepoint&quot; triggers savepoints for a running job or disposes existing ones.</span><br><span class="line"></span><br><span class="line">  Syntax: savepoint [OPTIONS] &lt;Job ID&gt; [&lt;target directory&gt;]</span><br><span class="line">  &quot;savepoint&quot; action options:</span><br><span class="line">     -d,--dispose &lt;arg&gt;       Path of savepoint to dispose.</span><br><span class="line">     -j,--jarfile &lt;jarfile&gt;   Flink program JAR file.</span><br><span class="line">  Options for yarn-cluster mode:</span><br><span class="line">     -m,--jobmanager &lt;arg&gt;            Address of the JobManager (master) to</span><br><span class="line">                                      which to connect. Use this flag to connect</span><br><span class="line">                                      to a different JobManager than the one</span><br><span class="line">                                      specified in the configuration.</span><br><span class="line">     -yid,--yarnapplicationId &lt;arg&gt;   Attach to running YARN session</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;    Namespace to create the Zookeeper</span><br><span class="line">                                      sub-paths for high availability mode</span><br><span class="line"></span><br><span class="line">  Options for default mode:</span><br><span class="line">     -m,--jobmanager &lt;arg&gt;           Address of the JobManager (master) to which</span><br><span class="line">                                     to connect. Use this flag to connect to a</span><br><span class="line">                                     different JobManager than the one specified</span><br><span class="line">                                     in the configuration.</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;   Namespace to create the Zookeeper sub-paths</span><br><span class="line">                                     for high availability mode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Please specify an action.</span><br><span class="line">[double_happy@hadoop101 bin]$</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">./flink  run [OPTIONS] &lt;jar-file&gt; &lt;arguments&gt; </span><br><span class="line"></span><br><span class="line">注意：  提交jar  运行 命令</span><br><span class="line"></span><br><span class="line">./flink run \</span><br><span class="line">--class com.sx.flink04.SocketWindowWordCount \</span><br><span class="line">/home/double_happy/lib/Flink-1.0.jar \</span><br><span class="line">--port 9998 \</span><br><span class="line">--host hadoop101</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">提交结果：</span><br><span class="line">[double_happy@hadoop101 bin]$ ./flink run \</span><br><span class="line">&gt; --class com.sx.flink04.SocketWindowWordCount \</span><br><span class="line">&gt; /home/double_happy/lib/Flink-1.0.jar \</span><br><span class="line">&gt; --port 9998 \</span><br><span class="line">&gt; --host hadoop101</span><br><span class="line">Starting execution of program</span><br></pre></td></tr></table></figure></div>

<p><img src="https://img-blog.csdnimg.cn/20200105210441990.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>点进去</strong><br><img src="https://img-blog.csdnimg.cn/20200105210608282.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">nc 生产一些数据：</span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 ~]$ nc -lk 9998</span><br><span class="line">a,a,a,a,bb,c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">那么这些数据在Flink 哪里呢？</span><br><span class="line"></span><br><span class="line">点击 Task Managers： 能看到很多参数的 ***</span><br><span class="line">	1.能看到 jvm的 参数 </span><br><span class="line">	2.Network 相关的</span><br></pre></td></tr></table></figure></div>

<p><img src="https://img-blog.csdnimg.cn/20200105210959821.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">这些日志哪里来的？</span><br><span class="line">	就是从文件系统读进来的</span><br></pre></td></tr></table></figure></div>
<p><img src="https://img-blog.csdnimg.cn/20200105211034704.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">结果：</span><br><span class="line">	1.通过 页面可以看的到的 （就是从本地结果 传到页面上的 ）</span><br><span class="line">	2.通过本地也能看到</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">本地查看：</span><br><span class="line">	[double_happy@hadoop101 log]$ tail -200f flink-double_happy-taskexecutor-1-hadoop101.out</span><br><span class="line">	WordWithCount(a,1)</span><br><span class="line">	WordWithCount(a,2)</span><br><span class="line">	WordWithCount(a,3)</span><br><span class="line">	WordWithCount(a,4)</span><br><span class="line">	WordWithCount(bb,1)</span><br><span class="line">	WordWithCount(c,1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">	$ tail -f log/flink-*-taskexecutor-*.out  </span><br><span class="line">就可以看到本地 结果</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">如何停止这个作业：</span><br><span class="line">	1.页面 上 running jos 点进去 </span><br><span class="line">	2.本地命令</span><br></pre></td></tr></table></figure></div>
<p><img src="https://img-blog.csdnimg.cn/20200105211557264.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">本地命令：</span><br><span class="line">	 ./flink  cancel [OPTIONS] &lt;Job ID&gt;</span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 bin]$ ./flink cancel 710a899ba9589d6a688c14931f7ef6cd</span><br><span class="line">Cancelling job 710a899ba9589d6a688c14931f7ef6cd.</span><br><span class="line">Cancelled job 710a899ba9589d6a688c14931f7ef6cd.</span><br><span class="line">[double_happy@hadoop101 bin]$</span><br></pre></td></tr></table></figure></div>
<p><img src="https://img-blog.csdnimg.cn/20200105212016595.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">关闭集群：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 bin]$ jps</span><br><span class="line">4688 TaskManagerRunner</span><br><span class="line">4258 StandaloneSessionClusterEntrypoint</span><br><span class="line">9444 Jps</span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 bin]$ ./stop-cluster.sh </span><br><span class="line">Stopping taskexecutor daemon (pid: 4688) on host hadoop101.</span><br><span class="line">Stopping standalonesession daemon (pid: 4258) on host hadoop101.</span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 bin]$ jps</span><br><span class="line">10457 Jps</span><br><span class="line">[double_happy@hadoop101 bin]$</span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">	页面也就打不开了</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">以上：</span><br><span class="line">	就是最简单的local模式 运行jar  job</span><br></pre></td></tr></table></figure></div>

<h2 id="对比Spark-shell"><a href="#对比Spark-shell" class="headerlink" title="对比Spark-shell"></a>对比Spark-shell</h2><p><strong>start-scala-shell.sh</strong> </p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[double_happy@hadoop101 bin]$ ./start-scala-shell.sh </span><br><span class="line">Starting Flink Shell:</span><br><span class="line">log4j:WARN No appenders could be found for logger (org.apache.flink.configuration.GlobalConfiguration).</span><br><span class="line">log4j:WARN Please initialize the log4j system properly.</span><br><span class="line">log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.</span><br><span class="line">Error: please specify execution mode:</span><br><span class="line">[local | remote &lt;host&gt; &lt;port&gt; | yarn]</span><br><span class="line">[double_happy@hadoop101 bin]$ </span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">	Error: please specify execution mode: 指定跑在什么模式下 </span><br><span class="line">	Spark和Flink都可以跑在多个模式上的</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">[double_happy@hadoop101 bin]$ ./start-scala-shell.sh local</span><br><span class="line">Starting Flink Shell:</span><br><span class="line"></span><br><span class="line">Starting local Flink cluster (host: localhost, port: 8081).</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Connecting to Flink cluster (host: localhost, port: 8081).</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                         ▒▓██▓██▒</span><br><span class="line">                     ▓████▒▒█▓▒▓███▓▒</span><br><span class="line">                  ▓███▓░░        ▒▒▒▓██▒  ▒</span><br><span class="line">                ░██▒   ▒▒▓▓█▓▓▒░      ▒████</span><br><span class="line">                ██▒         ░▒▓███▒    ▒█▒█▒</span><br><span class="line">                  ░▓█            ███   ▓░▒██</span><br><span class="line">                    ▓█       ▒▒▒▒▒▓██▓░▒░▓▓█</span><br><span class="line">                  █░ █   ▒▒░       ███▓▓█ ▒█▒▒▒</span><br><span class="line">                  ████░   ▒▓█▓      ██▒▒▒ ▓███▒</span><br><span class="line">               ░▒█▓▓██       ▓█▒    ▓█▒▓██▓ ░█░</span><br><span class="line">         ▓░▒▓████▒ ██         ▒█    █▓░▒█▒░▒█▒</span><br><span class="line">        ███▓░██▓  ▓█           █   █▓ ▒▓█▓▓█▒</span><br><span class="line">      ░██▓  ░█░            █  █▒ ▒█████▓▒ ██▓░▒</span><br><span class="line">     ███░ ░ █░          ▓ ░█ █████▒░░    ░█░▓  ▓░</span><br><span class="line">    ██▓█ ▒▒▓▒          ▓███████▓░       ▒█▒ ▒▓ ▓██▓</span><br><span class="line"> ▒██▓ ▓█ █▓█       ░▒█████▓▓▒░         ██▒▒  █ ▒  ▓█▒</span><br><span class="line"> ▓█▓  ▓█ ██▓ ░▓▓▓▓▓▓▓▒              ▒██▓           ░█▒</span><br><span class="line"> ▓█    █ ▓███▓▒░              ░▓▓▓███▓          ░▒░ ▓█</span><br><span class="line"> ██▓    ██▒    ░▒▓▓███▓▓▓▓▓██████▓▒            ▓███  █</span><br><span class="line">▓███▒ ███   ░▓▓▒░░   ░▓████▓░                  ░▒▓▒  █▓</span><br><span class="line">█▓▒▒▓▓██  ░▒▒░░░▒▒▒▒▓██▓░                            █▓</span><br><span class="line">██ ▓░▒█   ▓▓▓▓▒░░  ▒█▓       ▒▓▓██▓    ▓▒          ▒▒▓</span><br><span class="line">▓█▓ ▓▒█  █▓░  ░▒▓▓██▒            ░▓█▒   ▒▒▒░▒▒▓█████▒</span><br><span class="line"> ██░ ▓█▒█▒  ▒▓▓▒  ▓█                █░      ░░░░   ░█▒</span><br><span class="line"> ▓█   ▒█▓   ░     █░                ▒█              █▓</span><br><span class="line">  █▓   ██         █░                 ▓▓        ▒█▓▓▓▒█░</span><br><span class="line">   █▓ ░▓██░       ▓▒                  ▓█▓▒░░░▒▓█░    ▒█</span><br><span class="line">    ██   ▓█▓░      ▒                    ░▒█▒██▒      ▓▓</span><br><span class="line">     ▓█▒   ▒█▓▒░                         ▒▒ █▒█▓▒▒░░▒██</span><br><span class="line">      ░██▒    ▒▓▓▒                     ▓██▓▒█▒ ░▓▓▓▓▒█▓</span><br><span class="line">        ░▓██▒                          ▓░  ▒█▓█  ░░▒▒▒</span><br><span class="line">            ▒▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░▓▓  ▓░▒█░</span><br><span class="line"></span><br><span class="line">              F L I N K - S C A L A - S H E L L</span><br><span class="line"></span><br><span class="line">NOTE: Use the prebound Execution Environments and Table Environment to implement batch or streaming programs.</span><br><span class="line"></span><br><span class="line">  Batch - Use the &apos;benv&apos; and &apos;btenv&apos; variable</span><br><span class="line"></span><br><span class="line">    * val dataSet = benv.readTextFile(&quot;/path/to/data&quot;)</span><br><span class="line">    * dataSet.writeAsText(&quot;/path/to/output&quot;)</span><br><span class="line">    * benv.execute(&quot;My batch program&quot;)</span><br><span class="line">    *</span><br><span class="line">    * val batchTable = btenv.fromDataSet(dataSet)</span><br><span class="line">    * btenv.registerTable(&quot;tableName&quot;, batchTable)</span><br><span class="line">    * val result = btenv.sqlQuery(&quot;SELECT * FROM tableName&quot;).collect</span><br><span class="line">    HINT: You can use print() on a DataSet to print the contents or collect()</span><br><span class="line">    a sql query result back to the shell.</span><br><span class="line"></span><br><span class="line">  Streaming - Use the &apos;senv&apos; and &apos;stenv&apos; variable</span><br><span class="line"></span><br><span class="line">    * val dataStream = senv.fromElements(1, 2, 3, 4)</span><br><span class="line">    * dataStream.countWindowAll(2).sum(0).print()</span><br><span class="line">    *</span><br><span class="line">    * val streamTable = stenv.fromDataStream(dataStream, &apos;num)</span><br><span class="line">    * val resultTable = streamTable.select(&apos;num).where(&apos;num % 2 === 1 )</span><br><span class="line">    * resultTable.toAppendStream[Row].print()</span><br><span class="line">    * senv.execute(&quot;My streaming program&quot;)</span><br><span class="line">    HINT: You can only print a DataStream to the shell in local mode.</span><br><span class="line">      </span><br><span class="line"></span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意：</span><br><span class="line">	  Batch - Use the &apos;benv&apos; and &apos;btenv&apos; variable</span><br><span class="line">	  Streaming - Use the &apos;senv&apos; and &apos;stenv&apos; variable</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">批处理：</span><br><span class="line">scala&gt; val text = benv.fromElements(&quot;kairis,kairis,kairis&quot;,&quot;double_happy,sxwang&quot;)</span><br><span class="line">text: org.apache.flink.api.scala.DataSet[String] = org.apache.flink.api.scala.DataSet@26a004ed</span><br><span class="line"></span><br><span class="line">scala&gt; text.flatMap(_.split(&quot;,&quot;)).map((_,1)).groupBy(0).sum(1).print</span><br><span class="line">(double_happy,1)</span><br><span class="line">(kairis,3)</span><br><span class="line">(sxwang,1)</span><br><span class="line"></span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure></div>
<h2 id="跑在Yarn上"><a href="#跑在Yarn上" class="headerlink" title="跑在Yarn上 ***"></a>跑在Yarn上 ***</h2><div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">面试题：谈谈你对Flink ON YARN执行流程的理解？</span><br><span class="line"></span><br><span class="line">	和Spark mr 都差不多 只是 ApplicaitonMaster 名字变了</span><br></pre></td></tr></table></figure></div>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/ops/deployment/yarn_setup.html#yarn-setup" target="_blank" rel="noopener">YARN Setup</a><br><img src="https://img-blog.csdnimg.cn/20200105214018381.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/ops/deployment/yarn_setup.html#background--internals" target="_blank" rel="noopener">Background / Internals</a></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">The YARN client needs to access the Hadoop configuration to connect to the YARN resource manager and HDFS</span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">	YARN client 要配置gateway</span><br><span class="line"></span><br><span class="line">但是：</span><br><span class="line">	Flink跑yarn 跟Spark 跑yarn 有点区别</span><br><span class="line"></span><br><span class="line">为什么呢？</span><br><span class="line">	Flink有两种模式跑yarn</span><br><span class="line">		1.Start a long-running Flink cluster on YARN</span><br><span class="line">			启动一个长服务</span><br><span class="line">		2.Run a Flink job on YARN</span><br></pre></td></tr></table></figure></div>
<p><img src="https://img-blog.csdnimg.cn/20200105215637367.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Spark里面 就是 右边这种  </span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">	Spark申请资源是耗时的 还记得吗 依赖的 jar包需要传到hdfs上 也不然每次都要传 还记得么</span><br><span class="line"></span><br><span class="line">这两种方式会带来什么好处：</span><br><span class="line">	1.长服务 </span><br><span class="line">			省资源申请的时间</span><br></pre></td></tr></table></figure></div>
<p><strong>两种方式分别演示</strong></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"> ./yarn-session.sh  运行的时候有坑的 ：</span><br><span class="line"> 	1.你自己源码编译好的是没有问题的</span><br><span class="line"> 	2.不是编译的 要在flink lib包下面 加一个 lib哦</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 bin]$ ./yarn-session.sh --help</span><br><span class="line">2020-01-05 22:32:14,068 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: jobmanager.rpc.address, hadoop101</span><br><span class="line">2020-01-05 22:32:14,070 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: jobmanager.rpc.port, 6123</span><br><span class="line">2020-01-05 22:32:14,070 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: jobmanager.heap.size, 1024m</span><br><span class="line">2020-01-05 22:32:14,070 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: taskmanager.heap.size, 1024m</span><br><span class="line">2020-01-05 22:32:14,070 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: taskmanager.numberOfTaskSlots, 1</span><br><span class="line">2020-01-05 22:32:14,070 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: parallelism.default, 1</span><br><span class="line">2020-01-05 22:32:14,071 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: jobmanager.execution.failover-strategy, region</span><br><span class="line">2020-01-05 22:32:14,071 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: rest.port, 8081</span><br><span class="line">2020-01-05 22:32:14,667 WARN  org.apache.hadoop.util.NativeCodeLoader                       - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">2020-01-05 22:32:14,923 INFO  org.apache.flink.runtime.security.modules.HadoopModule        - Hadoop user set to double_happy (auth:SIMPLE)</span><br><span class="line">Usage:</span><br><span class="line">   Required</span><br><span class="line">     -n,--container &lt;arg&gt;   Number of YARN container to allocate (=Number of Task Managers)</span><br><span class="line">   Optional</span><br><span class="line">     -at,--applicationType &lt;arg&gt;     Set a custom application type for the application on YARN</span><br><span class="line">     -D &lt;property=value&gt;             use value for given property</span><br><span class="line">     -d,--detached                   If present, runs the job in detached mode</span><br><span class="line">     -h,--help                       Help for the Yarn session CLI.</span><br><span class="line">     -id,--applicationId &lt;arg&gt;       Attach to running YARN session</span><br><span class="line">     -j,--jar &lt;arg&gt;                  Path to Flink jar file</span><br><span class="line">     -jm,--jobManagerMemory &lt;arg&gt;    Memory for JobManager Container with optional unit (default: MB)</span><br><span class="line">     -m,--jobmanager &lt;arg&gt;           Address of the JobManager (master) to which to connect. Use this flag to connect to a different JobManager than the one specified in the configuration.</span><br><span class="line">     -n,--container &lt;arg&gt;            Number of YARN container to allocate (=Number of Task Managers)</span><br><span class="line">     -nl,--nodeLabel &lt;arg&gt;           Specify YARN node label for the YARN application</span><br><span class="line">     -nm,--name &lt;arg&gt;                Set a custom name for the application on YARN</span><br><span class="line">     -q,--query                      Display available YARN resources (memory, cores)</span><br><span class="line">     -qu,--queue &lt;arg&gt;               Specify YARN queue.</span><br><span class="line">     -s,--slots &lt;arg&gt;                Number of slots per TaskManager</span><br><span class="line">     -sae,--shutdownOnAttachedExit   If the job is submitted in attached mode, perform a best-effort cluster shutdown when the CLI is terminated abruptly, e.g., in response to a user interrupt, such</span><br><span class="line">                                     as typing Ctrl + C.</span><br><span class="line">     -st,--streaming                 Start Flink in streaming mode</span><br><span class="line">     -t,--ship &lt;arg&gt;                 Ship files in the specified directory (t for transfer)</span><br><span class="line">     -tm,--taskManagerMemory &lt;arg&gt;   Memory per TaskManager Container with optional unit (default: MB)</span><br><span class="line">     -yd,--yarndetached              If present, runs the job in detached mode (deprecated; use non-YARN specific option instead)</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;   Namespace to create the Zookeeper sub-paths for high availability mode</span><br><span class="line">[double_happy@hadoop101 bin]$</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">  Required</span><br><span class="line">     -n,--container &lt;arg&gt;   Number of YARN container to allocate (=Number of Task Managers)</span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">	必填的 </span><br><span class="line">	-n   就是 container   =  Number of Task Managers </span><br><span class="line"></span><br><span class="line">不是必填的：</span><br><span class="line">  -jm,--jobManagerMemory &lt;arg&gt;    Memory for JobManager Container with optional unit (default: MB)</span><br><span class="line"> -tm,--taskManagerMemory &lt;arg&gt;   Memory per TaskManager Container with optional unit (default: MB)</span><br><span class="line">    -d,--detached                   If present, runs the job in detached mode     运行你的job 以什么方式</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">运行起来：</span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 bin]$ ./yarn-session.sh -n 2 -jm 1024 -tm 1024 -d </span><br><span class="line"></span><br><span class="line">2020-01-05 22:37:43,651 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: jobmanager.rpc.address, hadoop101</span><br><span class="line">2020-01-05 22:37:43,656 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: jobmanager.rpc.port, 6123</span><br><span class="line">2020-01-05 22:37:43,656 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: jobmanager.heap.size, 1024m</span><br><span class="line">2020-01-05 22:37:43,657 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: taskmanager.heap.size, 1024m</span><br><span class="line">2020-01-05 22:37:43,657 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: taskmanager.numberOfTaskSlots, 1</span><br><span class="line">2020-01-05 22:37:43,657 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: parallelism.default, 1</span><br><span class="line">2020-01-05 22:37:43,658 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: jobmanager.execution.failover-strategy, region</span><br><span class="line">2020-01-05 22:37:43,658 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: rest.port, 8081</span><br><span class="line">2020-01-05 22:37:44,328 WARN  org.apache.hadoop.util.NativeCodeLoader                       - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">2020-01-05 22:37:44,505 INFO  org.apache.flink.runtime.security.modules.HadoopModule        - Hadoop user set to double_happy (auth:SIMPLE)</span><br><span class="line">2020-01-05 22:37:44,611 INFO  org.apache.hadoop.yarn.client.RMProxy                         - Connecting to ResourceManager at /0.0.0.0:8032</span><br><span class="line">2020-01-05 22:37:44,761 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - The argument n is deprecated in will be ignored.</span><br><span class="line">2020-01-05 22:37:44,930 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Cluster specification: ClusterSpecification&#123;masterMemoryMB=1024, taskManagerMemoryMB=1024, numberTaskManagers=2, slotsPerTaskManager=1&#125;</span><br><span class="line">2020-01-05 22:37:45,573 WARN  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - The configuration directory (&apos;/home/double_happy/app/flink-1.9.1/conf&apos;) contains both LOG4J and Logback configuration files. Please delete or rename one of them.</span><br><span class="line">2020-01-05 22:37:47,853 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Submitting application master application_1578233120766_0002</span><br><span class="line">2020-01-05 22:37:48,255 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl         - Submitted application application_1578233120766_0002</span><br><span class="line">2020-01-05 22:37:48,255 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Waiting for the cluster to be allocated</span><br><span class="line">2020-01-05 22:37:48,257 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Deploying cluster, current state ACCEPTED</span><br><span class="line">2020-01-05 22:37:58,915 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - YARN application has been deployed successfully.</span><br><span class="line">2020-01-05 22:37:58,915 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - The Flink YARN client has been started in detached mode. In order to stop Flink on YARN, use the following command or a YARN web interface to stop it:</span><br><span class="line">yarn application -kill application_1578233120766_0002</span><br><span class="line">Please also note that the temporary files of the YARN session in the home directory will not be removed.</span><br><span class="line">2020-01-05 22:37:59,734 INFO  org.apache.flink.runtime.rest.RestClient                      - Rest client endpoint started.</span><br><span class="line">Flink JobManager is now running on hadoop101:8081 with leader id 00000000-0000-0000-0000-000000000000.</span><br><span class="line">JobManager Web Interface: http://hadoop101:8081</span><br><span class="line">2020-01-05 22:37:59,757 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - The Flink YARN client has been started in detached mode. In order to stop Flink on YARN, use the following command or a YARN web interface to stop it:</span><br><span class="line">yarn application -kill application_1578233120766_0002</span><br><span class="line">[double_happy@hadoop101 bin]$</span><br></pre></td></tr></table></figure></div>
<p>去yarn 上查看：<br><img src="https://img-blog.csdnimg.cn/20200105223922233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">运行一个 例子试试：</span><br><span class="line">	Example</span><br><span class="line"></span><br><span class="line">wget -O LICENSE-2.0.txt http://www.apache.org/licenses/LICENSE-2.0.txt</span><br><span class="line">hadoop fs -copyFromLocal LICENSE-2.0.txt hdfs:/// ...</span><br><span class="line">./bin/flink run ./examples/batch/WordCount.jar \</span><br><span class="line">       --input hdfs:///..../LICENSE-2.0.txt --output hdfs:///.../wordcount-result.txt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">	这是啥意思呀：</span><br><span class="line">		就是把数据 上传到hdfs上 然后运行</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[double_happy@hadoop101 data]$ hadoop fs -put ./LICENSE-2.0.txt /flink/input/</span><br><span class="line">put: `/flink/input/&apos;: No such file or directory</span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 data]$ hadoop fs -mkdir -p  /flink/input/</span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 data]$ hadoop fs -put ./LICENSE-2.0.txt /flink/input/    </span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 data]$ hadoop fs -ls /flink/input/</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   1 double_happy supergroup      11358 2020-01-05 22:43 /flink/input/LICENSE-2.0.txt</span><br><span class="line">[double_happy@hadoop101 data]$</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">运行：</span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 flink]$ ./bin/flink run ./examples/batch/WordCount.jar \</span><br><span class="line">&gt; --input hdfs://hadoop101:8020/flink/input/LICENSE-2.0.txt \</span><br><span class="line">&gt; --output hdfs://hadoop101:8020/flink/output</span><br><span class="line">2020-01-05 22:46:46,517 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - Found Yarn properties file under /tmp/.yarn-properties-double_happy.</span><br><span class="line">2020-01-05 22:46:46,517 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - Found Yarn properties file under /tmp/.yarn-properties-double_happy.</span><br><span class="line">2020-01-05 22:46:47,119 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - YARN properties set default parallelism to 2</span><br><span class="line">2020-01-05 22:46:47,119 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - YARN properties set default parallelism to 2</span><br><span class="line">YARN properties set default parallelism to 2</span><br><span class="line">2020-01-05 22:46:47,238 INFO  org.apache.hadoop.yarn.client.RMProxy                         - Connecting to ResourceManager at /0.0.0.0:8032</span><br><span class="line">2020-01-05 22:46:47,449 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - No path for the flink jar passed. Using the location of class org.apache.flink.yarn.YarnClusterDescriptor to locate the jar</span><br><span class="line">2020-01-05 22:46:47,449 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - No path for the flink jar passed. Using the location of class org.apache.flink.yarn.YarnClusterDescriptor to locate the jar</span><br><span class="line">2020-01-05 22:46:47,650 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Found application JobManager host name &apos;hadoop101&apos; and port &apos;8081&apos; from supplied application id &apos;application_1578233120766_0002&apos;</span><br><span class="line">Starting execution of program</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">结果：</span><br><span class="line">[double_happy@hadoop101 flink]$ hadoop fs -ls /flink/output</span><br><span class="line">-rw-r--r--   1 double_happy supergroup       4499 2020-01-05 22:47 /flink/output</span><br><span class="line">[double_happy@hadoop101 flink]$ hadoop fs -text /flink/output</span><br><span class="line">0 3</span><br><span class="line">1 2</span><br><span class="line">2 4</span><br><span class="line">2004 1</span><br><span class="line">3 1</span><br><span class="line">4 1</span><br><span class="line">5 1</span><br><span class="line">50 1</span><br><span class="line">6 1</span><br><span class="line">7 1</span><br><span class="line">8 1</span><br><span class="line">9 2</span><br><span class="line">a 22</span><br><span class="line">above 1</span><br><span class="line">acceptance 1</span><br><span class="line">accepting 3</span><br><span class="line">act 1</span><br><span class="line">acting 1</span><br><span class="line">acts 1</span><br><span class="line">add 2</span><br><span class="line">addendum 1</span><br><span class="line">additional 5</span><br><span class="line">additions 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">	Flink输出的 是文件 </span><br><span class="line">	Spark是文件夹</span><br></pre></td></tr></table></figure></div>

<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">注意：</span><br><span class="line">	这个模式 他怎么知道是提交到 哪个session上去呢？</span><br><span class="line"></span><br><span class="line">看控制台log：</span><br><span class="line">2020-01-05 22:46:46,517 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli              </span><br><span class="line">   - Found Yarn properties file under /tmp/.yarn-properties-double_happy.</span><br><span class="line"></span><br><span class="line">打开： /tmp/.yarn-properties-double_happy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 flink]$ cat /tmp/.yarn-properties-double_happy</span><br><span class="line">#Generated YARN properties file</span><br><span class="line">#Sun Jan 05 22:37:59 CST 2020</span><br><span class="line">parallelism=2</span><br><span class="line">dynamicPropertiesString=</span><br><span class="line">applicationID=application_1578233120766_0002     //yarn 的 application的 id</span><br><span class="line">[double_happy@hadoop101 flink]$</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">	这块 如果你已经使用了 这个模式跑 之后 还想使用 local跑 </span><br><span class="line">	需要把/tmp/.yarn-properties-double_happy  这个 干掉 也不然 本地模式会 跑到yarn上 报错</span><br></pre></td></tr></table></figure></div>
<p><strong>Run a single Flink job on YARN</strong><br><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/ops/deployment/yarn_setup.html#run-a-single-flink-job-on-yarn" target="_blank" rel="noopener">Run a single Flink job on YARN</a></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br></pre></td><td class="code"><pre><span class="line">官方案例：</span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 flink]$ ./bin/flink run -m yarn-cluster ./examples/batch/WordCount.jar</span><br><span class="line">2020-01-05 23:06:06,559 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - Found Yarn properties file under /tmp/.yarn-properties-double_happy.</span><br><span class="line">2020-01-05 23:06:06,559 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - Found Yarn properties file under /tmp/.yarn-properties-double_happy.</span><br><span class="line">2020-01-05 23:06:07,151 INFO  org.apache.hadoop.yarn.client.RMProxy                         - Connecting to ResourceManager at /0.0.0.0:8032</span><br><span class="line">2020-01-05 23:06:07,324 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - No path for the flink jar passed. Using the location of class org.apache.flink.yarn.YarnClusterDescriptor to locate the jar</span><br><span class="line">2020-01-05 23:06:07,324 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - No path for the flink jar passed. Using the location of class org.apache.flink.yarn.YarnClusterDescriptor to locate the jar</span><br><span class="line">2020-01-05 23:06:07,520 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Cluster specification: ClusterSpecification&#123;masterMemoryMB=1024, taskManagerMemoryMB=1024, numberTaskManagers=1, slotsPerTaskManager=1&#125;</span><br><span class="line">2020-01-05 23:06:08,127 WARN  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - The configuration directory (&apos;/home/double_happy/app/flink-1.9.1/conf&apos;) contains both LOG4J and Logback configuration files. Please delete or rename one of them.</span><br><span class="line">2020-01-05 23:06:10,927 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Submitting application master application_1578233120766_0003</span><br><span class="line">2020-01-05 23:06:10,965 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl         - Submitted application application_1578233120766_0003</span><br><span class="line">2020-01-05 23:06:10,966 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Waiting for the cluster to be allocated</span><br><span class="line">2020-01-05 23:06:10,971 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Deploying cluster, current state ACCEPTED</span><br><span class="line">2020-01-05 23:06:18,402 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - YARN application has been deployed successfully.</span><br><span class="line">Starting execution of program</span><br><span class="line">Executing WordCount example with default input data set.</span><br><span class="line">Use --input to specify file input.</span><br><span class="line">Printing result to stdout. Use --output to specify output path.</span><br><span class="line">(a,5)</span><br><span class="line">(action,1)</span><br><span class="line">(after,1)</span><br><span class="line">(against,1)</span><br><span class="line">(all,2)</span><br><span class="line">(and,12)</span><br><span class="line">(arms,1)</span><br><span class="line">(arrows,1)</span><br><span class="line">(awry,1)</span><br><span class="line">(ay,1)</span><br><span class="line">(bare,1)</span><br><span class="line">(be,4)</span><br><span class="line">(bear,3)</span><br><span class="line">(bodkin,1)</span><br><span class="line">(bourn,1)</span><br><span class="line">(but,1)</span><br><span class="line">(by,2)</span><br><span class="line">(calamity,1)</span><br><span class="line">(cast,1)</span><br><span class="line">(coil,1)</span><br><span class="line">(come,1)</span><br><span class="line">(conscience,1)</span><br><span class="line">(consummation,1)</span><br><span class="line">(contumely,1)</span><br><span class="line">(country,1)</span><br><span class="line">(cowards,1)</span><br><span class="line">(currents,1)</span><br><span class="line">(d,4)</span><br><span class="line">(death,2)</span><br><span class="line">(delay,1)</span><br><span class="line">(despis,1)</span><br><span class="line">(devoutly,1)</span><br><span class="line">(die,2)</span><br><span class="line">(does,1)</span><br><span class="line">(dread,1)</span><br><span class="line">(dream,1)</span><br><span class="line">(dreams,1)</span><br><span class="line">(end,2)</span><br><span class="line">(enterprises,1)</span><br><span class="line">(er,1)</span><br><span class="line">(fair,1)</span><br><span class="line">(fardels,1)</span><br><span class="line">(flesh,1)</span><br><span class="line">(fly,1)</span><br><span class="line">(for,2)</span><br><span class="line">(fortune,1)</span><br><span class="line">(from,1)</span><br><span class="line">(give,1)</span><br><span class="line">(great,1)</span><br><span class="line">(grunt,1)</span><br><span class="line">(have,2)</span><br><span class="line">(he,1)</span><br><span class="line">(heartache,1)</span><br><span class="line">(heir,1)</span><br><span class="line">(himself,1)</span><br><span class="line">(his,1)</span><br><span class="line">(hue,1)</span><br><span class="line">(ills,1)</span><br><span class="line">(in,3)</span><br><span class="line">(insolence,1)</span><br><span class="line">(is,3)</span><br><span class="line">(know,1)</span><br><span class="line">(law,1)</span><br><span class="line">(life,2)</span><br><span class="line">(long,1)</span><br><span class="line">(lose,1)</span><br><span class="line">(love,1)</span><br><span class="line">(make,2)</span><br><span class="line">(makes,2)</span><br><span class="line">(man,1)</span><br><span class="line">(may,1)</span><br><span class="line">(merit,1)</span><br><span class="line">(might,1)</span><br><span class="line">(mind,1)</span><br><span class="line">(moment,1)</span><br><span class="line">(more,1)</span><br><span class="line">(mortal,1)</span><br><span class="line">(must,1)</span><br><span class="line">(my,1)</span><br><span class="line">(name,1)</span><br><span class="line">(native,1)</span><br><span class="line">(natural,1)</span><br><span class="line">(no,2)</span><br><span class="line">(nobler,1)</span><br><span class="line">(not,2)</span><br><span class="line">(now,1)</span><br><span class="line">(nymph,1)</span><br><span class="line">(o,1)</span><br><span class="line">(of,15)</span><br><span class="line">(off,1)</span><br><span class="line">(office,1)</span><br><span class="line">(ophelia,1)</span><br><span class="line">(opposing,1)</span><br><span class="line">(oppressor,1)</span><br><span class="line">(or,2)</span><br><span class="line">(orisons,1)</span><br><span class="line">(others,1)</span><br><span class="line">(outrageous,1)</span><br><span class="line">(pale,1)</span><br><span class="line">(pangs,1)</span><br><span class="line">(patient,1)</span><br><span class="line">(pause,1)</span><br><span class="line">(perchance,1)</span><br><span class="line">(pith,1)</span><br><span class="line">(proud,1)</span><br><span class="line">(puzzles,1)</span><br><span class="line">(question,1)</span><br><span class="line">(quietus,1)</span><br><span class="line">(rather,1)</span><br><span class="line">(regard,1)</span><br><span class="line">(remember,1)</span><br><span class="line">(resolution,1)</span><br><span class="line">(respect,1)</span><br><span class="line">(returns,1)</span><br><span class="line">(rub,1)</span><br><span class="line">(s,5)</span><br><span class="line">(say,1)</span><br><span class="line">(scorns,1)</span><br><span class="line">(sea,1)</span><br><span class="line">(shocks,1)</span><br><span class="line">(shuffled,1)</span><br><span class="line">(sicklied,1)</span><br><span class="line">(sins,1)</span><br><span class="line">(sleep,5)</span><br><span class="line">(slings,1)</span><br><span class="line">(so,1)</span><br><span class="line">(soft,1)</span><br><span class="line">(something,1)</span><br><span class="line">(spurns,1)</span><br><span class="line">(suffer,1)</span><br><span class="line">(sweat,1)</span><br><span class="line">(take,1)</span><br><span class="line">(takes,1)</span><br><span class="line">(than,1)</span><br><span class="line">(that,7)</span><br><span class="line">(the,22)</span><br><span class="line">(their,1)</span><br><span class="line">(them,1)</span><br><span class="line">(there,2)</span><br><span class="line">(these,1)</span><br><span class="line">(this,2)</span><br><span class="line">(those,1)</span><br><span class="line">(thought,1)</span><br><span class="line">(thousand,1)</span><br><span class="line">(thus,2)</span><br><span class="line">(thy,1)</span><br><span class="line">(time,1)</span><br><span class="line">(tis,2)</span><br><span class="line">(to,15)</span><br><span class="line">(traveller,1)</span><br><span class="line">(troubles,1)</span><br><span class="line">(turn,1)</span><br><span class="line">(under,1)</span><br><span class="line">(undiscover,1)</span><br><span class="line">(unworthy,1)</span><br><span class="line">(us,3)</span><br><span class="line">(we,4)</span><br><span class="line">(weary,1)</span><br><span class="line">(what,1)</span><br><span class="line">(when,2)</span><br><span class="line">(whether,1)</span><br><span class="line">(whips,1)</span><br><span class="line">(who,2)</span><br><span class="line">(whose,1)</span><br><span class="line">(will,1)</span><br><span class="line">(wish,1)</span><br><span class="line">(with,3)</span><br><span class="line">(would,2)</span><br><span class="line">(wrong,1)</span><br><span class="line">(you,1)</span><br><span class="line">Program execution finished</span><br><span class="line">Job with JobID 0af373b2d338811166328e7e1fca1fe1 has finished.</span><br><span class="line">Job Runtime: 10995 ms</span><br><span class="line">Accumulator Results: </span><br><span class="line">- fed80ecbe6107c17759a1be247abbdd4 (java.util.ArrayList) [170 elements]</span><br><span class="line"></span><br><span class="line">[double_happy@hadoop101 flink]$</span><br></pre></td></tr></table></figure></div>
<p><strong>运行一下 之前的local的 程序：</strong></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">运行一下 之前的local的 程序：</span><br><span class="line">[double_happy@hadoop101 flink]$ ./bin/flink run \</span><br><span class="line">&gt; --class com.sx.flink04.SocketWindowWordCount \</span><br><span class="line">&gt; -m yarn-cluster \</span><br><span class="line">&gt; /home/double_happy/lib/Flink-1.0.jar \</span><br><span class="line">&gt; --port 9998 \</span><br><span class="line">&gt; --host hadoop101</span><br><span class="line">2020-01-05 23:08:37,619 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - Found Yarn properties file under /tmp/.yarn-properties-double_happy.</span><br><span class="line">2020-01-05 23:08:37,619 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - Found Yarn properties file under /tmp/.yarn-properties-double_happy.</span><br><span class="line">2020-01-05 23:08:38,076 INFO  org.apache.hadoop.yarn.client.RMProxy                         - Connecting to ResourceManager at /0.0.0.0:8032</span><br><span class="line">2020-01-05 23:08:38,294 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - No path for the flink jar passed. Using the location of class org.apache.flink.yarn.YarnClusterDescriptor to locate the jar</span><br><span class="line">2020-01-05 23:08:38,294 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - No path for the flink jar passed. Using the location of class org.apache.flink.yarn.YarnClusterDescriptor to locate the jar</span><br><span class="line">2020-01-05 23:08:38,467 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Cluster specification: ClusterSpecification&#123;masterMemoryMB=1024, taskManagerMemoryMB=1024, numberTaskManagers=1, slotsPerTaskManager=1&#125;</span><br><span class="line">2020-01-05 23:08:39,079 WARN  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - The configuration directory (&apos;/home/double_happy/app/flink-1.9.1/conf&apos;) contains both LOG4J and Logback configuration files. Please delete or rename one of them.</span><br><span class="line">2020-01-05 23:08:40,769 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Submitting application master application_1578233120766_0004</span><br><span class="line">2020-01-05 23:08:41,006 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl         - Submitted application application_1578233120766_0004</span><br><span class="line">2020-01-05 23:08:41,007 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Waiting for the cluster to be allocated</span><br><span class="line">2020-01-05 23:08:41,010 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Deploying cluster, current state ACCEPTED</span><br><span class="line">2020-01-05 23:08:46,914 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - YARN application has been deployed successfully.</span><br><span class="line">Starting execution of program</span><br></pre></td></tr></table></figure></div>
<p><img src="https://img-blog.csdnimg.cn/2020010523100919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">输入数据：</span><br><span class="line">[double_happy@hadoop101 data]$ nc -lk 9998</span><br><span class="line">啊，a,a,a,v,b,c</span><br><span class="line">c,c,d,d,,b,b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">查看结果：</span><br></pre></td></tr></table></figure></div>
<p><img src="https://img-blog.csdnimg.cn/20200105231116600.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9kb3VibGVoYXBweS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<div class="highlight-box"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">这是yarn的两种方式：</span><br><span class="line"></span><br><span class="line">我使用的是第二种方式 ：</span><br><span class="line">	如果需要一个MySQL jar包该怎么传？</span><br><span class="line">		我接触flink 时间很短  我身边同事也不知道 他们经常搞Flink的 竟然不知道？ 就知道打胖包？ 绝对是不可以的</span><br></pre></td></tr></table></figure></div>

      
    </div>
    
      <footer class="article-footer">
        完
      </footer>
    
  </div>
  
    
<nav id="article-nav">
  <div class="article-nav-block">
    
      <a href="/2020/01/05/Kudu-Impala%E6%95%85%E9%9A%9C%E6%A1%88%E4%BE%8B01-double-happy/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption"></strong>
        <div class="article-nav-title">
          
            Kudu+Impala故障案例01--double_happy
          
        </div>
      </a>
    
  </div>
  <div class="article-nav-block">
    
      <a href="/2020/01/05/Flink03-double-happy/" id="article-nav-older" class="article-nav-link-wrap">
        <div class="article-nav-title">Flink03--double_happy</div>
        <strong class="article-nav-caption"></strong>
      </a>
    
  </div>
</nav>

    <link rel="stylesheet" href="/css/gitment.css"> 
<script src="/js/gitment.js"></script>

<div id="gitmentContainer"></div>

<script>
var gitment = new Gitment({
  owner: '',
  repo: '',
  oauth: {
    client_id: '',
    client_secret: '',
  },
})
gitment.render('gitmentContainer')
</script>

  
  
</article>
</section>
        <aside id="sidebar">
  
    <div class="widget-box">
  <div class="avatar-box">
    <img class="avatar" src="/images/default-avatar.jpg" title="图片来自网络"></img>
    <h3 class="avatar-name">
      
        DoubleHappy
      
    </h3>
    <p class="avatar-slogan">
      特别耐撕的大数据，资深的打酱油攻城狮。
    </p>
  </div>
</div>


  
    

  
    

  
    
  
    
  <div class="widget-box">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li></ul>
    </div>
  </div>

  
    
  <div class="widget-box">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/01/05/Kudu-Impala%E6%95%85%E9%9A%9C%E6%A1%88%E4%BE%8B01-double-happy/">Kudu+Impala故障案例01--double_happy</a>
          </li>
        
          <li>
            <a href="/2020/01/05/Flink04-double-happy/">Flink04--double_happy</a>
          </li>
        
          <li>
            <a href="/2020/01/05/Flink03-double-happy/">Flink03--double_happy</a>
          </li>
        
          <li>
            <a href="/2020/01/05/Flink02-double-happy/">Flink02--double_happy</a>
          </li>
        
          <li>
            <a href="/2020/01/05/Flink01-double-happy/">Flink01-double_happy</a>
          </li>
        
      </ul>
    </div>
  </div>

  
      <div class="widget-box">
    <h3 class="widget-title">友链</h3>
    <div class="widget">
      
        <a style="display: block;" href="https://liverrrr.fun/archives" title target='_blank'
        >一路眼瞎</a>
      
    </div>
  </div>

  
</aside>
      </div>
      <footer id="footer">
  <div class="foot-box global-width">
    &copy; 2020 DoubleHappy &nbsp;&nbsp;
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    &nbsp;|&nbsp;主题 <a href="https://github.com/yiluyanxia/hexo-theme-antiquity" target="_blank" rel="noopener">antiquity</a>
    <br>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv">不蒜子告之   阁下是第<span id="busuanzi_value_site_pv"></span>个访客</span>
  </div>
</footer>
      <script src="https://code.jquery.com/jquery-2.0.3.min.js"></script>
<script>
if (!window.jQuery) {
var script = document.createElement('script');
script.src = "/js/jquery-2.0.3.min.js";
document.body.write(script);
}
</script>


<script src="/js/script.js"></script>



    </div>
    <nav id="mobile-nav" class="mobile-nav-box">
  <div class="mobile-nav-img mobile-nav-top"></div>
  
    <a href="/archives" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
  <div class="mobile-nav-img  mobile-nav-bottom"></div>
</nav>    
  </div>
</body>
</html>